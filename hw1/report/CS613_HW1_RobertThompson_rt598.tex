\title{CS 613 - Machine Learning}
\author{
        Assignment 1 - Linear Regression\\
        Robert Thompson\\
}
\documentclass[12pt]{article}
\usepackage[margin=0.7in]{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage{comment}
\usepackage{amsmath}

\includecomment{versionB}
%\excludecomment{versionB}

\begin{document}
\maketitle


\section{Theory}
$X =
\begin{bmatrix}
	-2\\
	-5\\
	-3\\
	0\\
	-8\\
	-2\\
	1\\
	5\\
	-1\\
	6
\end{bmatrix},
Y = 
\begin{bmatrix}
	1\\
	-4\\	
	1\\
	3\\
	11\\
	5\\
	0\\
	-1\\
	-3\\
	1\\
\end{bmatrix}
$

\subsection{Add Bias Feature}\label{bias}
$X =
\begin{bmatrix}
	1 & -2\\
	1 & -5\\
	1 & -3\\
	1 & 0\\
	1 & -8\\
	1 & -2\\
	1 & 1\\
	1 & 5\\
	1 & -1\\
	1 & 6
\end{bmatrix},
Y = 
\begin{bmatrix}
	1\\
	-4\\	
	1\\
	3\\
	11\\
	5\\
	0\\
	-1\\
	-3\\
	1\\
\end{bmatrix}
$

\newpage
\subsection{Direct Solution}
$w = (X^TX)^{-1}X^TY$

% The same as np.dot(X.T, X)
\noindent $X^TX = \begin{bmatrix}
	1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\\
	-2 & -5 & -3 & 0 & -8 & -2 & 1 & 5 & -1 & 6
\end{bmatrix}
\begin{bmatrix}
	1 & -2\\
	1 & -5\\
	1 & -3\\
	1 & 0\\
	1 & -8\\
	1 & -2\\
	1 & 1\\
	1 & 5\\
	1 & -1\\
	1 & 6
\end{bmatrix}\\
$
$X^TX = 
\begin{bmatrix}
 10 & -9\\
-9 & 169\\
\end{bmatrix}\\
$
\hfill \break
\hfill \break

\noindent $(X^TX)^{-1} = 
\frac{1}{|(10*169)-(-9*-9)|}\begin{bmatrix}169 & 9\\ 9 & 10\end{bmatrix} = \frac{1}{1690-81}\begin{bmatrix}169 & 9\\ 9 & 10\end{bmatrix}=
\hfill \break
\frac{1}{1609}\begin{bmatrix}169 & 9\\ 9 & 10\end{bmatrix}=\begin{bmatrix}169/1609 & 9/1609\\ 9/1609 & 10/1609\end{bmatrix} = \begin{bmatrix}0.10503418 & 0.00559354\\ 0.00559354 & 0.00621504\end{bmatrix}\\
$

\hfill \break
\hfill \break
% Function variables setup
\noindent $(X^TX)^{-1}X^T = 
\begin{bmatrix}0.10503418 & 0.00559354\\ 0.00559354 & 0.00621504\end{bmatrix}
\begin{bmatrix}
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\\
-2 & -5 & -3 & 0 & -8 & -2 & 1 & 5 & -1 & 6
\end{bmatrix}\\
$
\hfill \break
\hfill \break

% Output
\noindent $(X^TX)^{-1}X^T =
\hfill \break
\hfill \break
\begin{bmatrix}
0.09384711 & 0.0770665 & 0.08825357 & 0.10503418 & 0.06028589 & 0.09384711 & 0.11062772 & 0.13300186  0.09944065 & 0.1385954\\
-0.00683654 & -0.02548167 & -0.01305158 & 0.00559354 & -0.04412679 & -0.00683654 0.01180858 & 0.03666874 & -0.0006215 & 0.04288378
\end{bmatrix}\\
$
\hfill \break
\hfill \break

% Function variables setup
\noindent $(X^TX)^-1X^TY = 
\hfill \break
\hfill \break
\begin{bmatrix}
0.09384711 & 0.0770665 & 0.08825357 & 0.10503418 & 0.06028589 & 0.09384711 & 0.11062772 & 0.13300186  0.09944065 & 0.1385954\\
-0.00683654 & -0.02548167 & -0.01305158 & 0.00559354 & -0.04412679 & -0.00683654 0.01180858 & 0.03666874 & -0.0006215 & 0.04288378
\end{bmatrix}\\
\begin{bmatrix}
	1\\
	-4\\	
	1\\
	3\\
	11\\
	5\\
	0\\
	-1\\
	-3\\
	1\\
\end{bmatrix}
= 
\begin{bmatrix}	1.0285891858297085 & -0.4126786824114355 \\\end{bmatrix}$
\\
\hfill \break
\hfill \break
$w = \begin{bmatrix}	1.0285891858297085 & -0.4126786824114355 \\\end{bmatrix}$
\\

\subsection{$\hat{Y}$ Predictions}
\begin{enumerate}
   \item Learned Model: $y=1.0285891858297085 + -0.4126786824114355x_{:,1}$
   \item Predictions
   \begin{itemize}
    \item $\hat{Y} = 
        \begin{bmatrix}
        	1.85394655\\
        	3.0919826\\	
        	2.26662523\\
        	1.02858919\\
        	4.33001865\\
        	1.85394655\\
        	0.6159105\\
        	-1.03480423\\
        	1.44126787\\
        	-1.44748291\\
        \end{bmatrix}$
   \end{itemize}
\end{enumerate}

\subsection{RMSE and MAPE}

\begin{enumerate}
   \item Root Mean Squared Error (RMSE): 3.7013259176662716
   \item Mean Absolute Squared Error (MAPE): 142.73053114282442
\end{enumerate}

\newpage
\section{Closed Form (Direct) Linear Regression}

\begin{enumerate}
   \item Final Model: $y=-131.04963658130077 + 4.159936830388848x_{:,1} + 0.03081935892004047x_{:,2}$
   \item Training Output
   \begin{itemize}
     \item Root Mean Squared Error (RMSE): $19.86256862907285$
     \item Mean Absolute Percentage Error (MAPE): $21.397596050628863$
   \end{itemize}
   \item Validation Output
   \begin{itemize}
    \item Root Mean Squared Error (RMSE): $20.067704981328184$
    \item Mean Absolute Percentage Error (MAPE): $30.47810152100226$
   \end{itemize}
\end{enumerate}

\section{S-Folds Cross-Validation}\label{linreg}

\begin{enumerate}
   \item With S-Fold = 4
   \begin{itemize}
     \item Mean of RMSE: $21.599081781852323$
     \item Standard Deviation of RMSE: $2.5030965382840233$
   \end{itemize}
   
   \item With S-Fold = 11
   \begin{itemize}
     \item Mean of RMSE: $21.092988359747313$
     \item Standard Deviation of RMSE: $2.2987280583430545$
   \end{itemize}
   
   \item With S-Fold = 22
   \begin{itemize}
     \item Mean of RMSE: $19.725759616288194$
     \item Standard Deviation of RMSE: $1.7199475688764514$
   \end{itemize}
   
   \item With S-Fold = N
   \begin{itemize}
     \item Mean of RMSE: $20.994992352914746$
     \item Standard Deviation of RMSE: $2.709926830954012$
   \end{itemize}
\end{enumerate}

\section{Locally-Weighted Linear Regression}
\begin{enumerate}
    \item Validation Root Mean Squared Error (RMSE): $26.396286898865213$
    \item Validation Mean Absolute Percentage Error (MAPE): $28.76650617672107$
\end{enumerate}

\end{document}