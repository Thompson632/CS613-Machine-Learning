\title{CS 613 - Machine Learning}
\author{
        Assignment 1 - Linear Regression\\
        Robert Thompson\\
}
\documentclass[12pt]{article}
\usepackage[margin=0.7in]{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage{comment}
\usepackage{amsmath}

\includecomment{versionB}
%\excludecomment{versionB}

\begin{document}
\maketitle


\section{Theory}
$X =
\begin{bmatrix}
	-2\\
	-5\\
	-3\\
	0\\
	-8\\
	-2\\
	1\\
	5\\
	-1\\
	6
\end{bmatrix},
Y = 
\begin{bmatrix}
	1\\
	-4\\	
	1\\
	3\\
	11\\
	5\\
	0\\
	-1\\
	-3\\
	1\\
\end{bmatrix}
$

\subsection{Add Bias Feature}
$X =
\begin{bmatrix}
	1 & -2\\
	1 & -5\\
	1 & -3\\
	1 & 0\\
	1 & -8\\
	1 & -2\\
	1 & 1\\
	1 & 5\\
	1 & -1\\
	1 & 6
\end{bmatrix},
Y = 
\begin{bmatrix}
	1\\
	-4\\	
	1\\
	3\\
	11\\
	5\\
	0\\
	-1\\
	-3\\
	1\\
\end{bmatrix}
$

\newpage
\subsection{Direct Solution}
Matrices below are rounded to four decimals places due to page space limitations but the resulting weights (coefficients) and $\hat{Y}$ predictions contain all decimal places.

\hfill \break
\hfill \break

$w = (X^TX)^{-1}X^TY$

\noindent $X^TX = \begin{bmatrix}
	1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\\
	-2 & -5 & -3 & 0 & -8 & -2 & 1 & 5 & -1 & 6
\end{bmatrix}
\begin{bmatrix}
	1 & -2\\
	1 & -5\\
	1 & -3\\
	1 & 0\\
	1 & -8\\
	1 & -2\\
	1 & 1\\
	1 & 5\\
	1 & -1\\
	1 & 6
\end{bmatrix}\\
$
$X^TX = 
\begin{bmatrix}
 10 & -9\\
-9 & 169\\
\end{bmatrix}\\
$

\hfill \break
\hfill \break

\noindent $(X^TX)^{-1} = 
\frac{1}{|(10*169)-(-9*-9)|}\begin{bmatrix}169 & 9\\ 9 & 10\end{bmatrix} = \frac{1}{1690-81}\begin{bmatrix}169 & 9\\ 9 & 10\end{bmatrix}=
\hfill \break
\frac{1}{1609}\begin{bmatrix}169 & 9\\ 9 & 10\end{bmatrix}=\begin{bmatrix}169/1609 & 9/1609\\ 9/1609 & 10/1609\end{bmatrix} = \begin{bmatrix}0.1050 & 0.0056\\ 0.0056 & 0.0062\end{bmatrix}\\
$

\hfill \break
\hfill \break

\noindent $(X^TX)^{-1}X^T = 
\begin{bmatrix}0.1050 & 0.0056\\ 0.0056 & 0.0062\end{bmatrix}
\begin{bmatrix}
1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\\
-2 & -5 & -3 & 0 & -8 & -2 & 1 & 5 & -1 & 6
\end{bmatrix}\\
$
\hfill \break
\hfill \break

\noindent $(X^TX)^{-1}X^T =
\hfill \break
\hfill \break
\begin{bmatrix}
0.0938 & 0.0770 & 0.0883 & 0.1050 & 0.0603 & 0.0938 & 0.1106 & 0.1330 & 0.0994 & 0.1386\\
-0.0068 & -0.0255 & -0.0130 & 0.0056 & -0.0441 & -0.0068 & 0.0118 & 0.0367 & -0.0006 & 0.0429
\end{bmatrix}\\
$
\hfill \break
\hfill \break

\noindent $(X^TX)^-1X^TY = 
\hfill \break
\hfill \break
\begin{bmatrix}
0.0938 & 0.0770 & 0.0883 & 0.1050 & 0.0603 & 0.0938 & 0.1106 & 0.1330 & 0.0994 & 0.1386\\
-0.0068 & -0.0255 & -0.0130 & 0.0056 & -0.0441 & -0.0068 & 0.0118 & 0.0367 & -0.0006 & 0.0429
\end{bmatrix}\\
\hfill \break
\hfill \break
\begin{bmatrix}
	1\\
	-4\\	
	1\\
	3\\
	11\\
	5\\
	0\\
	-1\\
	-3\\
	1\\
\end{bmatrix}
= 
\begin{bmatrix}	1.0285891858297085 & -0.4126786824114355 \\\end{bmatrix}$
\\
\hfill \break
\hfill \break
$w = \begin{bmatrix}	1.0285891858297085 & -0.4126786824114355 \\\end{bmatrix}$
\\

\subsection{$\hat{Y}$ Predictions}
\begin{enumerate}
   \item Learned Model: $y=1.0285891858297085 + -0.4126786824114355x_{:,1}$
   \item Predictions
   \begin{itemize}
    \item $\hat{Y} = 
        \begin{bmatrix}
        	1.85394655\\
        	3.0919826\\	
        	2.26662523\\
        	1.02858919\\
        	4.33001865\\
        	1.85394655\\
        	0.6159105\\
        	-1.03480423\\
        	1.44126787\\
        	-1.44748291\\
        \end{bmatrix}$
   \end{itemize}
\end{enumerate}

\subsection{RMSE and MAPE}

\begin{enumerate}
   \item Root Mean Squared Error (RMSE): 3.7013259176662716
   \item Mean Absolute Percentage Error (MAPE) as Percent: 142.73053114282442
   \item Mean Absolute Percentage Error (MAPE) as Decimal: 1.42730531143
\end{enumerate}

\newpage
\section{Closed Form (Direct) Linear Regression}

\begin{enumerate}
   \item Final Model: $y=-131.04963658130077 + 4.159936830388848x_{:,1} + 0.03081935892004047x_{:,2}$
   \item Training Output
   \begin{itemize}
     \item Root Mean Squared Error (RMSE): $19.86256862907285$
     \item Mean Absolute Percentage Error (MAPE) as Percent: $21.397596050628863$
     \item Mean Absolute Percentage Error (MAPE) as Decimal: $0.2139759605$
   \end{itemize}
   \item Validation Output
   \begin{itemize}
    \item Root Mean Squared Error (RMSE): $20.067704981328184$
    \item Mean Absolute Percentage Error (MAPE) as Percent: $30.47810152100226$
    \item Mean Absolute Percentage Error (MAPE) as Decimal: $0.30478101521$
   \end{itemize}
\end{enumerate}

\section{S-Folds Cross-Validation}\label{linreg}

\begin{enumerate}
   \item With S-Fold = 4
   \begin{itemize}
     \item Mean of RMSE: $21.599081781852323$
     \item Standard Deviation of RMSE: $2.5030965382840233$
   \end{itemize}
   
   \item With S-Fold = 11
   \begin{itemize}
     \item Mean of RMSE: $21.092988359747313$
     \item Standard Deviation of RMSE: $2.2987280583430545$
   \end{itemize}
   
   \item With S-Fold = 22
   \begin{itemize}
     \item Mean of RMSE: $19.725759616288194$
     \item Standard Deviation of RMSE: $1.7199475688764514$
   \end{itemize}
   
   \item With S-Fold = N
   \begin{itemize}
     \item Mean of RMSE: $20.994992352914746$
     \item Standard Deviation of RMSE: $2.709926830954012$
   \end{itemize}
\end{enumerate}

\section{Locally-Weighted Linear Regression}
\begin{enumerate}
    \item Validation Root Mean Squared Error (RMSE): $26.396286898865213$
    \item Validation Mean Absolute Percentage Error (MAPE) Percent: $28.76650617672107$
    \item Validation Mean Absolute Percentage Error (MAPE) as Decimal: $0.28766506176$
\end{enumerate}

\end{document}